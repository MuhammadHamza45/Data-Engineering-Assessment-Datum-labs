# Monthly Active Users (MAU) for January 2024:Count of unique users active in January 2024.

from pyspark.sql.functions import to_date, col
from pyspark.sql.types import StructType, StructField, IntegerType, StringType

# Define the schema and create DataFrame
schema = StructType([
    StructField("activity_id", IntegerType(), True),
    StructField("user_id", IntegerType(), True),
    StructField("activity_date", StringType(), True)  # Use StringType here
])

data = [
    (1, 101, "2024-01-05"),
    (2, 102, "2024-01-06"),
    (3, 103, "2024-01-07"),
    (4, 101, "2024-01-15"),
    (5, 104, "2024-01-20"),
    (6, 102, "2024-01-25"),
    (7, 105, "2024-01-30")
]

df_userActivity = spark.createDataFrame(data, schema=schema)

# Convert activity_date col to date type
df_userActivity = df_userActivity.withColumn("activity_date", to_date(df_userActivity["activity_date"], "yyyy-MM-dd"))
#df_userActivity.show()

# Filter data for January 2024
filter_data = df_userActivity.filter((col("activity_date") >= "2024-01-01") & (col("activity_date") <= "2024-01-31"))
#filter_data.show()

# Count unique user_id from filter_data
mau = filter_data.select("user_id").distinct().count()

print(f"MAU for January 2024: {mau}")
